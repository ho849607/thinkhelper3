from fastapi import FastAPI
from pydantic import BaseModel
from typing import List, Literal, Optional
import google.generativeai as genai
import os # ğŸ‘ˆ 1. os ëª¨ë“ˆ ê°€ì ¸ì˜¤ê¸°

# ğŸ‘ˆ 2. ì½”ë“œì—ì„œ í‚¤ ì‚­ì œ! ëŒ€ì‹  í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì½ê¸°
GEMINI_API_KEY = os.environ.get("GEMINI_API_KEY") 

if not GEMINI_API_KEY:
    print("ğŸ”´ ì¹˜ëª…ì  ì˜¤ë¥˜: GEMINI_API_KEY í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    # (ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì—¬ê¸°ì„œ ì„œë²„ê°€ êº¼ì§€ë„ë¡ ì²˜ë¦¬í•  ìˆ˜ë„ ìˆìŒ)
else:
    genai.configure(api_key=GEMINI_API_KEY)

app = FastAPI()
model = genai.GenerativeModel('gemini-1.5-flash') # (í‚¤ê°€ ìˆì„ ë•Œë§Œ ì´ˆê¸°í™”ë˜ë„ë¡ ìˆ˜ì •)

class Message(BaseModel):
    role: Literal["user", "assistant", "system"]
    content: str

class ApiPayload(BaseModel):
    action: str
    prompt: Optional[str] = None
    query: Optional[str] = None
    history: Optional[List[Message]] = None

@app.get("/")
def read_root():
    return {"Hello": "ThinkHelper Server"}

@app.post("/api/thinkhelper")
async def handle_api_call(payload: ApiPayload):
    
    if not GEMINI_API_KEY:
        # í—¬í¼ 1.0 ì‘ë‹µ (API í‚¤ ì—†ì„ ë•Œ)
        response_text = f"(ì„œë²„ í—¬í¼ 1.0) '{payload.prompt or payload.query}' (ì„œë²„ì— API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤)"
        return {"ok": True, "text": response_text, "modelUsed": "helper_1.0_no_key"}

    if payload.action == "chat":
        try:
            user_message = payload.prompt or ""
            response = await model.generate_content_async(user_message)
            return { "ok": True, "text": response.text, "modelUsed": "Gemini 1.5 Flash" }
        except Exception as e:
            return {"ok": False, "error": str(e), "text": f"AI ì‘ë‹µ ì˜¤ë¥˜ (ì„œë²„): {e}"}

    elif payload.action == "search":
        # ... (ê²€ìƒ‰ ë¡œì§ êµ¬í˜„) ...
        return {"ok": False, "error": "ê²€ìƒ‰ ê¸°ëŠ¥ì€ ì•„ì§ êµ¬í˜„ ì¤‘ì…ë‹ˆë‹¤."}
        
    return {"ok": False, "error": "ì•Œ ìˆ˜ ì—†ëŠ” actionì…ë‹ˆë‹¤."}
